{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple Translation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMGRzSHW315+PqJFH/1rs5w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fbelinchon/HuggingFace_ES/blob/main/Simple_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hA5fm79VlY_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fd03952-c376-4c7d-e41f-0e6c207c7e1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.8 MB 25.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 59.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 63.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 52.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 51.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -qq install transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vamos a implementar un modelo de traducción usando diferentes métodos\n"
      ],
      "metadata": {
        "id": "3F7o6xx1BYXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Método Simple: Pipeline"
      ],
      "metadata": {
        "id": "jazlE5znEClP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es la forma más sencilla pero que nos ofrece menos personalizaciones.\n",
        "\n",
        "Pasos:\n",
        "* Importamos el objeto pipeline\n",
        "* Le pasamos el tipo de tarea (\"translation\") y elmodelo a utilizar (Helsinki-NLP/opus-mt-es-en)\n",
        "\n",
        "Al objeto resultante le podemos pasar una lista de sentencias en español y nos devolvera el listado de traducciones."
      ],
      "metadata": {
        "id": "CnE_-bXsEH6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "wpUrgaT7Bc4n"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"Helsinki-NLP/opus-mt-es-en\"\n",
        "translator = pipeline(\"translation\",model=checkpoint)"
      ],
      "metadata": {
        "id": "SpbRf0fwBsKy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(translator([\"Hola este es mi perro\",\"No encuentro donde he dejado mi coche\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLM0NmIwB8YD",
        "outputId": "15bd96e5-deef-4678-e296-010e725a2e37"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'translation_text': 'Hey, this is my dog.'}, {'translation_text': \"I can't find where I left my car.\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Método más detallado"
      ],
      "metadata": {
        "id": "vWDQZ8UhE6eq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso vamos a realizar manualmente los pasos que se realizan con el objeto pipeline.\n",
        "\n",
        "Pasos:\n",
        "* Obtenemos el tokenizador asociado al modelo que vamos a utilizar.\n",
        "* Obtenemos el modelo en sí (ya preentrenado).\n",
        "* Convertimos nuestro texto a token.\n",
        "* Los tokens del paso anterior los convertimos a números.\n",
        "* El listado de números será la entrada al modelo. Los modelos de redes neuronales solamente pueden trabajar con números.\n",
        "* La salida será un conjunto de números que tendremos que decodificar para obtener las sentencias traducidas"
      ],
      "metadata": {
        "id": "FSoSwqcWE-I0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "checkpoint = \"Helsinki-NLP/opus-mt-es-en\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint,use_fast=False)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "JKF8HWcRlns3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traducir=[\"Hola este es mi perro.\"]\n",
        "\n",
        "batch = tokenizer(traducir,padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hObuKPIhlusb",
        "outputId": "25e2923b-4298-43f6-e433-f46f476be312"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[2119,  104,   43,  155, 8693,    3,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar que el resultado el resultadoes un diccionario con:\n",
        "* inputs_id: La representación númerica de las palabras de la sentencia a traducir.\n",
        "* attention_mask: máscara que nos permite gestionar varias sentencias de diferentes longitudes a la vez.\n",
        "\n",
        "Vamos a comprobar que si decodificamos la misma secuencia de números nos da la frase en palabras.\n"
      ],
      "metadata": {
        "id": "CU8DAS_1GsQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode([2119,104,43,155,8693,3,0])"
      ],
      "metadata": {
        "id": "63l2JGIDJ34a",
        "outputId": "e31c9635-adec-4c94-8c72-a61055a257e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'▁Hola▁este es mi▁perro.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a gestionar una lista de sentencias para ver el funcionamiento de padding=true y el significado de attention_mask"
      ],
      "metadata": {
        "id": "Po2NqkRKKbez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traducir=[\"Hola este es mi perro\",\"No encuentro donde he dejado mi coche\"]\n",
        "\n",
        "batch = tokenizer(traducir,padding=True, truncation=True, return_tensors=\"pt\")\n",
        "print(batch)"
      ],
      "metadata": {
        "id": "hwDl6NzOIYgw",
        "outputId": "d9e432eb-85f6-4c44-fe16-e63002651357",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 2119,   104,    43,   155,  8693,     0, 65000, 65000],\n",
            "        [   71,  6585,   542,    95,  7131,   155,  2638,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comos e puede apreciar las dos sentencias tienen distintas longitudes. Con padding=True indicamos que se añadan caracteres especiales al final de la sentencia más corta hasta que las dos sentencias tengan la misma longitud.\n",
        "\n",
        "Si nos fijamos el attention_mask podemos ver que en la primera sentencia tenemos ceros en los dosúltimos token que son los que se han añadido para que tenga la misma longitud que la segunda sentencia. Esto indica al modelo que no utilice esos dos caracteres para calcular la atencción.\n",
        "\n",
        "Vemos que si decodificamos la primera sentencias nos aparecen los caracteres de relleno al final <pad>."
      ],
      "metadata": {
        "id": "EfPGW_bRKrGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode([2119,104,43,155,8693,0, 65000, 65000])"
      ],
      "metadata": {
        "id": "pMV-0gGuLis-",
        "outputId": "f7e604af-0a71-4ee5-88cb-4c9e57b4ba8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'▁Hola▁este es mi▁perro<pad><pad>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación usamos el diccionario batch como entrada a nuestro modelo."
      ],
      "metadata": {
        "id": "Cgw98TTXLwg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = model.generate(**batch)\n",
        "\n",
        "print(gen)"
      ],
      "metadata": {
        "id": "QWWIyeM7o5YF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b194d01-48dc-411c-acfb-a37804c2ffe8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[65000,  1068,     2,    58,    31,   125,  6913,     3,     0, 65000,\n",
            "         65000, 65000, 65000],\n",
            "        [65000,    33,    88,    20,    56,   634,   291,    33,  1263,   125,\n",
            "           785,     3,     0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La salida se corresponde con los números asignados a la traducción de lassentencias.\n",
        "\n",
        "Tenemos que pasarles el decodificador para obtener las palabras asociadas a esos números. El resultado es el mismo que el obtenido por el primer método."
      ],
      "metadata": {
        "id": "m9fduhIHMC0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.batch_decode(gen)"
      ],
      "metadata": {
        "id": "zGSWcW6jLfl3",
        "outputId": "8a90d13d-7cf9-45a2-898b-4b7f016a0e9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<pad> Hey, this is my dog.<pad><pad><pad><pad>',\n",
              " \"<pad> I can't find where I left my car.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.batch_decode(gen, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "qtJHCNxkMZiH",
        "outputId": "45c2b128-7788-494f-86ee-474c3be56e35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hey, this is my dog.', \"I can't find where I left my car.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bMbPpkdKMcLf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}