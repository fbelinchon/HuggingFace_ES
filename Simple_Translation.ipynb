{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple Translation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN9pvcVrN0uCc+ACokTXHSn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fbelinchon/HuggingFace_ES/blob/main/Simple_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hA5fm79VlY_b",
        "outputId": "6fd03952-c376-4c7d-e41f-0e6c207c7e1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.8 MB 25.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 59.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 63.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 52.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 51.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -qq install transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vamos a implementar un modelo de traducción usando diferentes métodos\n"
      ],
      "metadata": {
        "id": "3F7o6xx1BYXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Método Simple: Pipeline"
      ],
      "metadata": {
        "id": "jazlE5znEClP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es la forma más sencilla pero que nos ofrece menos personalizaciones.\n",
        "\n",
        "Pasos:\n",
        "* Importamos el objeto pipeline\n",
        "* Le pasamos el tipo de tarea (\"translation\") y elmodelo a utilizar (Helsinki-NLP/opus-mt-es-en)\n",
        "\n",
        "Al objeto resultante le podemos pasar una lista de sentencias en español y nos devolvera el listado de traducciones."
      ],
      "metadata": {
        "id": "CnE_-bXsEH6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "wpUrgaT7Bc4n"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"Helsinki-NLP/opus-mt-es-en\"\n",
        "translator = pipeline(\"translation\",model=checkpoint)"
      ],
      "metadata": {
        "id": "SpbRf0fwBsKy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(translator([\"Hola este es mi perro\",\"No encuentro donde he dejado mi coche\"]))"
      ],
      "metadata": {
        "id": "MLM0NmIwB8YD",
        "outputId": "15bd96e5-deef-4678-e296-010e725a2e37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'translation_text': 'Hey, this is my dog.'}, {'translation_text': \"I can't find where I left my car.\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Método más detallado"
      ],
      "metadata": {
        "id": "vWDQZ8UhE6eq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso vamos a realizar manualmente los pasos que se realizan con el objeto pipeline.\n",
        "\n",
        "Pasos:\n",
        "* Obtenemos el tokenizador asociado al modelo que vamos a utilizar.\n",
        "* Obtenemos el modelo en sí (ya preentrenado).\n",
        "* Convertimos nuestro texto a token.\n",
        "* Los tokens del paso anterior los convertimos a números.\n",
        "* El listadode números serála entrada al modelo.\n",
        "* La salida "
      ],
      "metadata": {
        "id": "FSoSwqcWE-I0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-es-en\",use_fast=False)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-es-en\")"
      ],
      "metadata": {
        "id": "JKF8HWcRlns3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch = tokenizer(\"Hola este es mi perro\", return_tensors=\"pt\")\n",
        "gen = model.generate(**batch)\n",
        "tokenizer.batch_decode(gen, skip_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hObuKPIhlusb",
        "outputId": "a78aa946-c1db-476a-c0e2-5a9dc5d33fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hey, this is my dog.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QWWIyeM7o5YF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}