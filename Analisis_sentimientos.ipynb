{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Analisis sentimientos.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN7y1w2Ryq7gRIbgbxupA6p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fbelinchon/HuggingFace_ES/blob/main/Analisis_sentimientos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BogLdzhxqqRa",
        "outputId": "c43b4948-3c88-4b54-c279-36e164519329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 30 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 40 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 51 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 61 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 71 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 81 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 92 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 102 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 112 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 122 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 133 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 143 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 153 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 163 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 174 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 184 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 194 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 204 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 215 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 225 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 235 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 245 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 256 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 266 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 276 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 286 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 296 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 307 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 317 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 325 kB 6.8 MB/s \n",
            "\u001b[?25hCollecting transformers[sentencepiece]\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 44.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 43.7 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 41.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
            "\u001b[K     |████████████████████████████████| 134 kB 53.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 41.9 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 70.6 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 42.6 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 45.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 45.7 MB/s \n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 37.5 MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 39.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (7.1.2)\n",
            "Installing collected packages: urllib3, multidict, frozenlist, yarl, pyyaml, asynctest, async-timeout, aiosignal, tokenizers, sacremoses, huggingface-hub, fsspec, aiohttp, xxhash, transformers, sentencepiece, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.0.0 frozenlist-1.3.0 fsspec-2022.2.0 huggingface-hub-0.4.0 multidict-6.0.2 pyyaml-6.0 responses-0.18.0 sacremoses-0.0.49 sentencepiece-0.1.96 tokenizers-0.11.6 transformers-4.17.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de análisis de sentimiento con HUgging face"
      ],
      "metadata": {
        "id": "5gGARR9xQkku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Método simple"
      ],
      "metadata": {
        "id": "Nw5RCnU1sNuU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizamos la función pipeline de Huggingface.\n",
        "\n",
        "1. Indicamos en el pipeline el tipo de tarea a realizar (sentiment-analysis)\n",
        "2. Tenemos que seleccionar un modelo de análisis de sentimiento en español. En este caso pysentimiento/robertuito-sentiment-analysis.\n"
      ],
      "metadata": {
        "id": "6tJxObXkQtKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "yqodpoLSqwAB"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = 'pysentimiento/robertuito-sentiment-analysis'\n",
        "\n",
        "sentimiento = pipeline('sentiment-analysis',model=checkpoint)"
      ],
      "metadata": {
        "id": "ReWbXVMmq4mn"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparamos una lsita de frases a analizar y llamamos al pipeline con la lista creada. El resultado el tipo de sentimiento para cada frase con su porcentaje de certidumbre."
      ],
      "metadata": {
        "id": "YX9LnfxhRVI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto=['Todo esto es perfecto','De lo malo lo peor','la silla es blanca']\n",
        "\n",
        "print(sentimiento(texto))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDxWT3nCreCA",
        "outputId": "1650651c-147c-4974-c366-16fb810921a8"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POS', 'score': 0.9886201620101929}, {'label': 'NEG', 'score': 0.9688207507133484}, {'label': 'NEU', 'score': 0.9894474744796753}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las etiquetas vienen definidas por el modelo y las podemos obtener de la siguiente forma."
      ],
      "metadata": {
        "id": "qBsA4jG2Rorl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentimiento.model.config.id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvE01-8sRyQr",
        "outputId": "ae5bbef5-8a2c-40a0-ac34-e10271d871d1"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'NEG', 1: 'NEU', 2: 'POS'}"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos cambiar el texto de las etiquetas simplemente asignando un nuevo diccionario con nuestro texto personalizado."
      ],
      "metadata": {
        "id": "XC6GXnVFR5pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentimiento.model.config.id2label={0: 'Negativo', 1: 'Neutro', 2: 'Positivo'}"
      ],
      "metadata": {
        "id": "dW_lQrPGSF8L"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentimiento(texto))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqAICst_SK0e",
        "outputId": "db24f96b-8729-4858-ecd3-5ddf62010c2a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'Positivo', 'score': 0.9886201620101929}, {'label': 'Negativo', 'score': 0.9688207507133484}, {'label': 'Neutro', 'score': 0.9894474744796753}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Método elaborado"
      ],
      "metadata": {
        "id": "whTDRfXKsRgv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos reproducir los mismoa pasos que"
      ],
      "metadata": {
        "id": "NyUTIR4dSt6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import  AutoTokenizer,AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "Ni7nAgHQr0Ft"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = 'pysentimiento/robertuito-sentiment-analysis'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "5rZhBch4spXp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto=['Todo esto es perfecto','De lo malo lo peor','la silla es blanca']\n",
        "batch = tokenizer(texto,padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF2C7ea8EFmU",
        "outputId": "fc54964d-e171-4d18-b797-7db4155f8950"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[   0,  658,  669,  442, 4976,    2,    1],\n",
            "        [   0,  413,  496, 3302,  496, 1599,    2],\n",
            "        [   0,  446, 8925,  442, 3367,    2,    1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 0]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentimiento = model(**batch)\n",
        "\n",
        "print(sentimiento)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCT5cM-FGiPF",
        "outputId": "106b8fc6-9452-40cb-b3d8-bf9debe24c87"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SequenceClassifierOutput(loss=None, logits=tensor([[-2.8312, -0.5093,  4.0487],\n",
            "        [ 2.9229, -0.6040, -2.9596],\n",
            "        [-1.2066,  3.6102, -2.3526]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import softmax\n",
        "\n",
        "prediccion = softmax(sentimiento.logits,dim=-1)\n",
        "print(prediccion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qxfBC5vHwjL",
        "outputId": "381bbbe8-2e94-4d4b-8700-e5eecb81a665"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0010, 0.0104, 0.9886],\n",
            "        [0.9688, 0.0285, 0.0027],\n",
            "        [0.0080, 0.9894, 0.0025]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqbr4m9oHxgA",
        "outputId": "9313ec1d-571a-4aee-9a05-d171ac660ef5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Negativo', 1: 'Neutro', 2: 'Positivo'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.id2label = {0: 'Negativo', 1: 'Neutro', 2: 'Positivo'}"
      ],
      "metadata": {
        "id": "tlTzdopRI-A4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a =np.array(np.argmax(prediccion.detach(),axis=1))"
      ],
      "metadata": {
        "id": "jQsIR3C5JJdA"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ind,valores in enumerate(zip(texto,a)):\n",
        "    frase=valores[0]\n",
        "    sentimiento=model.config.id2label[valores[1]]\n",
        "    porcentaje=prediccion.detach()[ind,valores[1]]\n",
        "\n",
        "    print(f'frase: \"{frase}\" con sentimiento {sentimiento} {porcentaje:.2f}%')\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckaLVMlYJhCb",
        "outputId": "8da4f93e-377d-442f-ab47-9eb7dae2cef2"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frase: \"Todo esto es perfecto\" con sentimiento Positivo 0.99%\n",
            "frase: \"De lo malo lo peor\" con sentimiento Negativo 0.97%\n",
            "frase: \"la silla es blanca\" con sentimiento Neutro 0.99%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PEoDXBjyPwbW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}